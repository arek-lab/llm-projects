{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607e0823-e265-4ebd-94b8-d8c5ab0471d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b2c555-beee-4eed-9894-42df37a5aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# import email\n",
    "# from googleapiclient.discovery import build\n",
    "# from google.oauth2.credentials import Credentials\n",
    "# from bs4 import BeautifulSoup\n",
    "# import base64\n",
    "# import re\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import chromadb\n",
    "# import tiktoken\n",
    "# from chromadb.utils import embedding_functions\n",
    "# import gradio as gr\n",
    "# import os\n",
    "# import shutil\n",
    "# ---------------------------------------------------\n",
    "import os\n",
    "import gradio as gr\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25e274-a88d-45c1-b0a7-4d262aaa1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\"\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ba820a-34c6-41ea-b389-2042ca0ae1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_doc(embeding_ready, file_path):\n",
    "    source_name = os.path.basename(file_path)\n",
    "    \n",
    "    doc = Document(page_content=embedding_ready, metadata={\"doc_name\": source_name})\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata[\"doc_name\"] = source_name\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb35f4b7-980e-4984-b462-1fd38a8a8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tromb\\anaconda3\\envs\\projects\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\anaconda3\\envs\\projects\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\anaconda3\\envs\\projects\\Lib\\site-packages\\gradio\\blocks.py\", line 2218, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\anaconda3\\envs\\projects\\Lib\\site-packages\\gradio\\blocks.py\", line 1729, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\anaconda3\\envs\\projects\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\anaconda3\\envs\\projects\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\anaconda3\\envs\\projects\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\anaconda3\\envs\\projects\\Lib\\site-packages\\gradio\\utils.py\", line 894, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\AppData\\Local\\Temp\\ipykernel_15684\\1122762986.py\", line 76, in process_user_file\n",
      "    chunks = chunk_doc(embedding_ready, user_file)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tromb\\AppData\\Local\\Temp\\ipykernel_15684\\1698293541.py\", line 4, in chunk_doc\n",
      "    doc = Document(page_content=embedding_ready, metadata={\"doc_name\": source_name})\n",
      "                                ^^^^^^^^^^^^^^^\n",
      "NameError: name 'embedding_ready' is not defined\n"
     ]
    }
   ],
   "source": [
    "# get file from user\n",
    "user_file = None\n",
    "\n",
    "def get_file_extension(file_path):\n",
    "    \"\"\"Zwraca rozszerzenie pliku, np. '.txt'.\"\"\"\n",
    "    return os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "def get_file_size_kb(file_path):\n",
    "    \"\"\"Zwraca rozmiar pliku w KB (z dokładnością do dwóch miejsc po przecinku).\"\"\"\n",
    "    size_bytes = os.path.getsize(file_path)\n",
    "    size_kb = size_bytes / 1024\n",
    "    return round(size_kb, 2)\n",
    "\n",
    "def detect_file_type(extension):\n",
    "    \"\"\"Rozpoznaje typ pliku na podstawie rozszerzenia.\"\"\"\n",
    "    types = {\n",
    "        '.txt': 'Text file',\n",
    "        '.pdf': 'PDF file',\n",
    "        '.md': 'Markdown file',\n",
    "        '.csv': 'CSV file'\n",
    "    }\n",
    "    return types.get(extension, 'Unknown file type')\n",
    "\n",
    "def get_file_from_user(file):\n",
    "    \"\"\"Główna funkcja – przyjmuje plik, sprawdza typ i rozmiar, zwraca opis jako tekst.\"\"\"\n",
    "    if file is None:\n",
    "        return \"No file uploaded.\"\n",
    "    \n",
    "    file_path = file.name  # Gradio File obj ma .name = path do pliku\n",
    "    global user_file\n",
    "    user_file = file_path  # ustawiamy globalnie, żeby process_user_file miało dostęp\n",
    "    extension = get_file_extension(file_path)\n",
    "    file_type = detect_file_type(extension)\n",
    "    file_size_kb = get_file_size_kb(file_path)\n",
    "\n",
    "    result = f\"File type: {file_type}\\nFile size: {file_size_kb} KB\"\n",
    "    return result\n",
    "\n",
    "def process_user_file():\n",
    "    global user_file\n",
    "    if user_file is None:\n",
    "        return \"No file to process. Please upload a file first.\"\n",
    "\n",
    "    file_size_kb = get_file_size_kb(user_file)\n",
    "    if file_size_kb > 10240:  # 10 MB = 10240 KB\n",
    "        return f\"File size: {file_size_kb} KB. Max file size is 10MB.\"\n",
    "\n",
    "    extension = get_file_extension(user_file)\n",
    "    file_type = detect_file_type(extension)\n",
    "\n",
    "    # Przygotowanie pliku w zależności od typu (tu prosta symulacja)\n",
    "    if extension == '.txt' or extension == '.md':\n",
    "        with open(user_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        embedding_ready = content  # np. surowy tekst dla embeddingu\n",
    "        info = f\"File ready for embedding. Type: {file_type}.\"\n",
    "    elif extension == '.csv':\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(user_file)\n",
    "        embedding_ready = df.to_json()  # np. konwersja dataframe do json stringa\n",
    "        info = f\"CSV file converted to JSON for embedding.\"\n",
    "    elif extension == '.pdf':\n",
    "        try:\n",
    "            from PyPDF2 import PdfReader\n",
    "            reader = PdfReader(user_file)\n",
    "            content = ''\n",
    "            for page in reader.pages:\n",
    "                content += page.extract_text() + '\\n'\n",
    "            embedding_ready = content\n",
    "            info = f\"PDF text extracted for embedding.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing PDF: {str(e)}\"\n",
    "    else:\n",
    "        return \"Unsupported file type for embedding.\"\n",
    "\n",
    "    chunks = chunk_doc(embedding_ready, user_file)\n",
    "    return len(chunks)\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"## Load your files and perform semantic search\")\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(elem_id=\"col2\"):\n",
    "            file_input = gr.File(label=\"Upload your file\")\n",
    "        with gr.Column():\n",
    "            file_output = gr.Textbox(label=\"File info\", interactive=False)\n",
    "            file_btn = gr.Button(\"Check file\")\n",
    "            embed_btn = gr.Button(\"Add to VectorBD\")\n",
    "    \n",
    "    file_btn.click(get_file_from_user, inputs=[file_input], outputs=[file_output])\n",
    "    embed_btn.click(process_user_file, outputs=[file_output])\n",
    "\n",
    "ui.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9362926b-034d-4b2c-b24a-1f940f4ed643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(raw_html):\n",
    "    \"\"\"Removes HTML tags and returns clean text.\"\"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_links(text):\n",
    "    \"\"\"Removes all HTTP/HTTPS links from the text.\"\"\"\n",
    "    url_pattern = r'https?://\\S+'\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "def get_header(headers, name):\n",
    "    \"\"\"Helper function to extract a specific header (e.g., Subject, From, Date).\"\"\"\n",
    "    for header in headers:\n",
    "        if header['name'].lower() == name.lower():\n",
    "            return header['value']\n",
    "    return None\n",
    "\n",
    "def clean_email_body(text):\n",
    "    \"\"\"Removes soft hyphens, zero-width spaces, and similar invisible characters from the text.\"\"\"\n",
    "    cleaned = re.sub(\n",
    "        r'[\\u2007\\u200b\\u200d\\u200e\\u200f\\u202a-\\u202e\\u2060\\u2061\\u2062\\u2063\\u2064\\ufeff\\u00ad]', \n",
    "        '', \n",
    "        text\n",
    "    )\n",
    "    return cleaned\n",
    "\n",
    "def get_message_body(payload):\n",
    "    \"\"\"\n",
    "    Recursively extracts the email body (text part only),\n",
    "    decodes it, cleans it from invisible characters, and removes links.\n",
    "    \"\"\"\n",
    "    if 'parts' in payload:\n",
    "        for part in payload['parts']:\n",
    "            if part['mimeType'] == 'text/plain':\n",
    "                data = part['body'].get('data')\n",
    "                if data:\n",
    "                    decoded_data = base64.urlsafe_b64decode(data).decode('utf-8')\n",
    "                    decoded_data = clean_email_body(decoded_data)\n",
    "                    clean_text = remove_links(decoded_data)\n",
    "                    return clean_text\n",
    "            else:\n",
    "                # Recursively check nested parts\n",
    "                result = get_message_body(part)\n",
    "                if result:\n",
    "                    return remove_links(result)\n",
    "    else:\n",
    "        if payload.get('mimeType') == 'text/plain':\n",
    "            data = payload['body'].get('data')\n",
    "            if data:\n",
    "                decoded_data = base64.urlsafe_b64decode(data).decode('utf-8')\n",
    "                decoded_data = clean_email_body(decoded_data)\n",
    "                return remove_links(decoded_data)\n",
    "    return \"\"\n",
    "\n",
    "def store_messages_in_dict(messages, service):\n",
    "    \"\"\"\n",
    "    Fetches messages and stores them in a list of dictionaries.\n",
    "    Each dictionary contains: id, date, sender, subject, and cleaned body text.\n",
    "    \"\"\"\n",
    "    emails_data = [] \n",
    "    if not messages:\n",
    "        print('No emails found.')\n",
    "    else:\n",
    "        for msg in messages:\n",
    "            msg_data = service.users().messages().get(userId='me', id=msg['id'], format='full').execute()\n",
    "            payload = msg_data.get('payload', {})\n",
    "            headers = payload.get('headers', [])\n",
    "\n",
    "            email = {\n",
    "                'id': msg['id'],\n",
    "                'date': get_header(headers, 'Date'),\n",
    "                'from': get_header(headers, 'From'),\n",
    "                'title': get_header(headers, 'Subject'),\n",
    "                'body': clean_html(get_message_body(payload))\n",
    "            }\n",
    "\n",
    "            emails_data.append(email)\n",
    "    return emails_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650fd56b-6774-4ac4-9ce7-036bfbd2b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "token_limit = 300\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "collection = client.get_or_create_collection(\"emails_collection\")\n",
    "\n",
    "def chunk_text(text, max_tokens=token_limit):\n",
    "    \"\"\"Splits the text into chunks limited by the number of tokens.\"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return [tokenizer.decode(tokens[i:i + max_tokens]) for i in range(0, len(tokens), max_tokens)]\n",
    "\n",
    "def embed_and_store_email(email):\n",
    "    \"\"\"Embeds and stores a single email into ChromaDB.\"\"\"\n",
    "    doc_id = email['id']\n",
    "    metadata_base = {\n",
    "        \"email_id\": doc_id,\n",
    "        \"from\": email['from'],\n",
    "        \"date\": email['date']\n",
    "    }\n",
    "\n",
    "    # Title embedding\n",
    "    title_embedding = embedding_model.encode([email['title']])[0]\n",
    "    collection.add(\n",
    "        documents=[email['title']],\n",
    "        metadatas=[{**metadata_base, \"part\": \"title\"}],\n",
    "        ids=[f\"{doc_id}_title\"],\n",
    "        embeddings=[title_embedding.tolist()]\n",
    "    )\n",
    "\n",
    "    # Body embedding with chunking\n",
    "    body_chunks = chunk_text(email['body'])\n",
    "    for idx, chunk in enumerate(body_chunks):\n",
    "        chunk_embedding = embedding_model.encode([chunk])[0]\n",
    "        collection.add(\n",
    "            documents=[chunk],\n",
    "            metadatas=[{**metadata_base, \"part\": f\"body_chunk_{idx}\"}],\n",
    "            ids=[f\"{doc_id}_body_chunk_{idx}\"],\n",
    "            embeddings=[chunk_embedding.tolist()]\n",
    "        )\n",
    "\n",
    "def process_and_store_emails(emails):\n",
    "    \"\"\"Processes a list of emails: embedding + storing into ChromaDB.\"\"\"\n",
    "    if not emails:\n",
    "        return \"No emails to process.\"\n",
    "\n",
    "    for email in emails:\n",
    "        embed_and_store_email(email)\n",
    "\n",
    "    return f\"Stored {len(emails)} emails in ChromaDB.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0cf04e1-46a5-4f36-b176-5b445cf3ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emails_from_gmail(maxEmails, batch_size=100):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', ['https://www.googleapis.com/auth/gmail.readonly'])\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "    all_messages = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(all_messages) < maxEmails:\n",
    "        remaining = maxEmails - len(all_messages)\n",
    "        this_batch_size = min(batch_size, remaining)  # the last batch may be smaller than batch_size\n",
    "\n",
    "        results = service.users().messages().list(\n",
    "            userId='me',\n",
    "            maxResults=this_batch_size,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        messages = results.get('messages', [])\n",
    "        all_messages.extend(messages)\n",
    "\n",
    "        next_page_token = results.get('nextPageToken')\n",
    "\n",
    "        if not next_page_token:\n",
    "            break  # no more emails to fetch\n",
    "\n",
    "    emails_data = store_messages_in_dict(all_messages, service)\n",
    "    process_and_store_emails(emails_data)\n",
    "    return (f'Done for {len(all_messages)} records')\n",
    "\n",
    "def save_credentials(file):\n",
    "    if file is None:\n",
    "        return \"No file to save.\"\n",
    "\n",
    "    filename = file.name.split(\"/\")[-1] \n",
    "    if filename != \"credentials.json\":\n",
    "        return \"Incorrect file name. Expected: credentials.json\"\n",
    " \n",
    "    dest_path = os.path.join(os.getcwd(), \"credentials.json\")\n",
    "    shutil.copy(file.name, dest_path)\n",
    "    return f\"File saved as {dest_path}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fc61293-b5b2-42ba-9781-d1bb61c44596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, num_results=5):\n",
    "    \"\"\"\n",
    "    Wyszukuje semantycznie podobne emaile w bazie ChromaDB\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not query.strip():\n",
    "            return \"Proszę wprowadzić zapytanie.\"\n",
    "        \n",
    "        # Sprawdź czy kolekcja ma jakieś dokumenty\n",
    "        collection_count = collection.count()\n",
    "        if collection_count == 0:\n",
    "            return \"Baza danych jest pusta. Najpierw pobierz emaile z Gmail.\"\n",
    "        \n",
    "        # Wykonaj wyszukiwanie semantyczne\n",
    "        results = collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=min(num_results, collection_count)\n",
    "        )\n",
    "        \n",
    "        if not results['documents'] or not results['documents'][0]:\n",
    "            return \"Nie znaleziono żadnych wyników dla tego zapytania.\"\n",
    "        \n",
    "        # Formatuj wyniki\n",
    "        formatted_results = []\n",
    "        documents = results['documents'][0]\n",
    "        metadatas = results['metadatas'][0] if results['metadatas'] else [{}] * len(documents)\n",
    "        distances = results['distances'][0] if results['distances'] else [0] * len(documents)\n",
    "\n",
    "        SIMILARITY_THRESHOLD = 1.2 \n",
    "        for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances)):\n",
    "            if distance > SIMILARITY_THRESHOLD:\n",
    "                if i == 0:  # jeśli nawet pierwszy wynik jest słaby\n",
    "                    return f\"Nie znaleziono podobnych emaili dla zapytania '{query}'. \\nNajlepszy wynik miał odległość {distance:.3f}, co wskazuje na słabe dopasowanie.\"\n",
    "                break  # przestań dodawać słabe wyniki\n",
    "            result_text = f\"**Wynik {i+1}** (odległość: {distance:.3f})\\n\"\n",
    "            \n",
    "            # Dodaj metadane jeśli są dostępne\n",
    "            if metadata:\n",
    "                if 'subject' in metadata:\n",
    "                    result_text += f\"**Temat:** {metadata['subject']}\\n\"\n",
    "                if 'sender' in metadata:\n",
    "                    result_text += f\"**Nadawca:** {metadata['sender']}\\n\"\n",
    "                if 'date' in metadata:\n",
    "                    result_text += f\"**Data:** {metadata['date']}\\n\"\n",
    "            \n",
    "            # Dodaj fragment treści (ograniczone do 300 znaków)\n",
    "            content_preview = doc[:300] + \"...\" if len(doc) > 300 else doc\n",
    "            result_text += f\"**Treść:** {content_preview}\\n\"\n",
    "            result_text += \"-\" * 50 + \"\\n\"\n",
    "            \n",
    "            formatted_results.append(result_text)\n",
    "        \n",
    "        return \"\\n\".join(formatted_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Błąd podczas wyszukiwania: {str(e)}\"\n",
    "\n",
    "def get_collection_stats():\n",
    "    \"\"\"\n",
    "    Zwraca statystyki kolekcji\n",
    "    \"\"\"\n",
    "    try:\n",
    "        count = collection.count()\n",
    "        return f\"Liczba emaili w bazie: {count}\"\n",
    "    except Exception as e:\n",
    "        return f\"Błąd przy pobieraniu statystyk: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3370c6a-bf15-4d00-a433-6db320ed7493",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_emails_from_gmail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m     email_output = gr.Textbox(label=\u001b[33m\"\u001b[39m\u001b[33mDownload status\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# output box to show download status\u001b[39;00m\n\u001b[32m     18\u001b[39m email_btn = gr.Button(\u001b[33m\"\u001b[39m\u001b[33mFetch emails\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# button to trigger fetching emails\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m email_btn.click(\u001b[43mget_emails_from_gmail\u001b[49m, inputs=[email_input], outputs=[email_output])\n\u001b[32m     21\u001b[39m gr.Markdown(\u001b[33m\"\u001b[39m\u001b[33m### Semantic search\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m gr.Row():\n",
      "\u001b[31mNameError\u001b[39m: name 'get_emails_from_gmail' is not defined"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"## Load your files and perform semantic search\")\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(elem_id=\"col2\"):\n",
    "            file_input = gr.File(label=\"Upload your file\")  # file upload input for credentials\n",
    "        with gr.Column():\n",
    "            file_output = gr.Textbox(label=\"File info\", interactive=False)\n",
    "            file_btn = gr.Button(\"Check file\")\n",
    "            embed_btn = gr.Button(\"Add to VectorBD\")\n",
    "    \n",
    "    file_btn.click(get_file_from_user, inputs=[file_input], outputs=[file_output])\n",
    "    embed_btn.click(process_user_file, outputs=[file_output])\n",
    "    \n",
    "\n",
    "    with gr.Row():\n",
    "        email_input = gr.Number(label=\"Number of emails to fetch\", value=10)  # input for number of emails to download\n",
    "        email_output = gr.Textbox(label=\"Download status\")  # output box to show download status\n",
    "\n",
    "    email_btn = gr.Button(\"Fetch emails\")  # button to trigger fetching emails\n",
    "    email_btn.click(get_emails_from_gmail, inputs=[email_input], outputs=[email_output])\n",
    "\n",
    "    gr.Markdown(\"### Semantic search\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            stats_output = gr.Textbox(label=\"Database statistics\", interactive=False)\n",
    "            stats_btn = gr.Button(\"Refresh statistics\")\n",
    "            stats_btn.click(get_collection_stats, outputs=[stats_output])\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            search_query = gr.Textbox(\n",
    "                label=\"Query\", \n",
    "                placeholder=\"E.g. 'meeting next week' or 'invoice for January'\",\n",
    "                lines=2\n",
    "            )\n",
    "            num_results = gr.Slider(\n",
    "                label=\"Number of results\", \n",
    "                minimum=1, \n",
    "                maximum=20, \n",
    "                value=5, \n",
    "                step=1\n",
    "            )\n",
    "            search_btn = gr.Button(\"Search\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            search_results = gr.Textbox(\n",
    "                label=\"Search results\", \n",
    "                lines=15, \n",
    "                interactive=False\n",
    "            )\n",
    "    \n",
    "    search_btn.click(\n",
    "        semantic_search, \n",
    "        inputs=[search_query, num_results], \n",
    "        outputs=[search_results]\n",
    "    )\n",
    "    \n",
    "ui.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726570c5-0ccb-4484-a57b-7ba97ca68e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
