{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e0823-e265-4ebd-94b8-d8c5ab0471d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2c555-beee-4eed-9894-42df37a5aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53754a7f-9d81-4d06-b16b-93e1a3c0d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = None \n",
    "retriever = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07ffa6-b338-4392-8089-bf5d823a53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DB_PATH = \"vector_db\"\n",
    "os.makedirs(VECTOR_DB_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25e274-a88d-45c1-b0a7-4d262aaa1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\"\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba820a-34c6-41ea-b389-2042ca0ae1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_doc(embedding_ready, file_path):\n",
    "    source_name = os.path.basename(file_path)\n",
    "    \n",
    "    doc = Document(page_content=embedding_ready, metadata={\"doc_name\": source_name})\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata[\"doc_name\"] = source_name\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ded6a7-26ae-4268-9f41-fdedf72b17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_db(chunks, db_name):\n",
    "    persist_path = os.path.join(\"vector_db\", db_name)\n",
    "    if os.path.exists(persist_path):\n",
    "        vectorstore = Chroma(persist_directory=persist_path, embedding_function=embeddings)\n",
    "        vectorstore.add_documents(chunks)\n",
    "    else:\n",
    "        vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=persist_path)\n",
    "    print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf135e-b900-4f9f-bf4e-0e3101bfbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdirectories(path=\".\"):\n",
    "    return [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "def refresh_db_list():\n",
    "    return gr.update(choices=get_subdirectories(\"vector_db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad547f-8a4d-4527-a8ab-ae2ac4869e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_active_vectorstore(selected_db):\n",
    "    global vectorstore, retriever\n",
    "\n",
    "    if not selected_db:\n",
    "        return \"No database selected.\"\n",
    "\n",
    "    persist_path = os.path.join(\"vector_db\", selected_db)\n",
    "    \n",
    "    if not os.path.exists(persist_path):\n",
    "        return f\"Database '{selected_db}' does not exist.\"\n",
    "\n",
    "    vectorstore = Chroma(persist_directory=persist_path, embedding_function=embeddings)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    return f\"Active VectorStore set to: {selected_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35f4b7-980e-4984-b462-1fd38a8a8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file from user\n",
    "user_file = None\n",
    "\n",
    "def get_file_extension(file_path):\n",
    "    \"\"\"Zwraca rozszerzenie pliku, np. '.txt'.\"\"\"\n",
    "    return os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "def get_file_size_kb(file_path):\n",
    "    \"\"\"Zwraca rozmiar pliku w KB (z dokładnością do dwóch miejsc po przecinku).\"\"\"\n",
    "    size_bytes = os.path.getsize(file_path)\n",
    "    size_kb = size_bytes / 1024\n",
    "    return round(size_kb, 2)\n",
    "\n",
    "def detect_file_type(extension):\n",
    "    \"\"\"Rozpoznaje typ pliku na podstawie rozszerzenia.\"\"\"\n",
    "    types = {\n",
    "        '.txt': 'Text file',\n",
    "        '.pdf': 'PDF file',\n",
    "        '.md': 'Markdown file',\n",
    "        '.csv': 'CSV file'\n",
    "    }\n",
    "    return types.get(extension, 'Unknown file type')\n",
    "\n",
    "def get_file_from_user(file, base_name_input, existing_db_selector):\n",
    "\n",
    "    if file is None:\n",
    "        return \"No file uploaded.\"\n",
    "\n",
    "    # Wybór bazy: najpierw input, jeśli pusty to dropdown\n",
    "    db_name = base_name_input.strip() if base_name_input and base_name_input.strip() else existing_db_selector\n",
    "\n",
    "    file_path = file.name  # Gradio File obj ma .name = path do pliku\n",
    "    global user_file\n",
    "    user_file = file_path  # ustawiamy globalnie, żeby process_user_file miało dostęp\n",
    "\n",
    "    extension = get_file_extension(file_path)\n",
    "    file_type = detect_file_type(extension)\n",
    "    file_size_kb = get_file_size_kb(file_path)\n",
    "\n",
    "    result = f\"File type: {file_type}\\nFile size: {file_size_kb} KB\\nDatabase name: {db_name if db_name else 'No database specified'}\"\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_user_file(base_name_input, existing_db_selector):\n",
    "    global user_file\n",
    "\n",
    "    db_name = base_name_input.strip() if base_name_input and base_name_input.strip() else existing_db_selector\n",
    "\n",
    "    if not db_name:\n",
    "        return \"No database name provided.\"\n",
    "        \n",
    "    if user_file is None:\n",
    "        return \"No file to process. Please upload a file first.\"\n",
    "\n",
    "    file_size_kb = get_file_size_kb(user_file)\n",
    "    if file_size_kb > 10240:  # 10 MB = 10240 KB\n",
    "        return f\"File size: {file_size_kb} KB. Max file size is 10MB.\"\n",
    "\n",
    "    extension = get_file_extension(user_file)\n",
    "    file_type = detect_file_type(extension)\n",
    "\n",
    "    # Przygotowanie pliku w zależności od typu (tu prosta symulacja)\n",
    "    if extension == '.txt' or extension == '.md':\n",
    "        with open(user_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        embedding_ready = content  # np. surowy tekst dla embeddingu\n",
    "        info = f\"File ready for embedding. Type: {file_type}.\"\n",
    "    elif extension == '.csv':\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(user_file)\n",
    "        embedding_ready = df.to_json()  # np. konwersja dataframe do json stringa\n",
    "        info = f\"CSV file converted to JSON for embedding.\"\n",
    "    elif extension == '.pdf':\n",
    "        try:\n",
    "            from PyPDF2 import PdfReader\n",
    "            reader = PdfReader(user_file)\n",
    "            content = ''\n",
    "            for page in reader.pages:\n",
    "                content += page.extract_text() + '\\n'\n",
    "            embedding_ready = content\n",
    "            info = f\"PDF text extracted for embedding.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing PDF: {str(e)}\"\n",
    "    else:\n",
    "        return \"Unsupported file type for embedding.\"\n",
    "\n",
    "    chunks = chunk_doc(embedding_ready, user_file)\n",
    "    add_to_db(chunks, db_name) \n",
    "    return f\"{info}\\nFile added to VectorDB: {db_name}\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e04681-e492-4abe-aba1-8f622a62c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "def chat_with_retrieval(query):\n",
    "    global retriever\n",
    "    if retriever is None:\n",
    "        return \"No VectorStore selected. Please select a database first.\"\n",
    "\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    result = conversation_chain.invoke({\"question\": query})\n",
    "    return result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e0e2c-ca48-4980-9c95-c7f1bf2d785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)\n",
    "\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8aa7f-7179-4d53-84ff-8b7f751116b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"## Load your files and perform semantic search with chatAI\")\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column():\n",
    "            file_input = gr.File(label=\"Upload your file\")\n",
    "        with gr.Column():\n",
    "            file_output = gr.Textbox(label=\"File info\", interactive=False)\n",
    "            with gr.Column():\n",
    "                with gr.Row():\n",
    "                    base_name_input = gr.Textbox(label=\"Give name new database\")\n",
    "                    existing_db_selector = gr.Dropdown(\n",
    "                    label=\"Or choose existing\",\n",
    "                    choices=get_subdirectories(\"vector_db\"),\n",
    "                    value=\"-- Choose vector DB --\",\n",
    "                    interactive=True,\n",
    "                    allow_custom_value=True\n",
    "                )\n",
    "                embed_btn = gr.Button(\"Add to VectorBD\")\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column():\n",
    "            db_selector = gr.Dropdown(\n",
    "                label=\"Choose database\",\n",
    "                choices=get_subdirectories(\"vector_db\"),\n",
    "                value=\"-- Choose vector DB --\",\n",
    "                interactive=True,\n",
    "                allow_custom_value=True\n",
    "            )\n",
    "            with gr.Row():\n",
    "                accept_button = gr.Button(\"Accept\")\n",
    "                refresh_button = gr.Button(\"Refresh DB List\")\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column():\n",
    "            gr.ChatInterface(chat, type=\"messages\")\n",
    "            \n",
    "        \n",
    "    \n",
    "    file_input.change(get_file_from_user, inputs=[file_input, base_name_input, existing_db_selector], outputs=[file_output])\n",
    "    embed_btn.click(process_user_file, inputs=[base_name_input, existing_db_selector], outputs=[file_output])\n",
    "\n",
    "    accept_button.click(set_active_vectorstore, inputs=[db_selector], outputs=[file_output])\n",
    "\n",
    "    refresh_button.click(refresh_db_list, outputs=[db_selector])\n",
    "\n",
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618e31a-30c2-4236-96cd-51a793b78d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
